{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q_mtlO0WNf2",
        "outputId": "ac4fc5b2-8a7d-4622-c6dc-1060b3e400cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVibPBqzWk2q",
        "outputId": "5fc69a9a-002c-4c65-d8e2-f315bd9f9c71"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Enhanced R-GCN Link Prediction Pipeline\n",
        "Features:\n",
        "- Comprehensive training metrics (Loss, AUC, AP, Hits@K, MRR)\n",
        "- Top-10 disease predictions per compound with positive/negative edge labels\n",
        "- Clean formatted output\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import RGCNConv\n",
        "from torch_geometric.data import HeteroData\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "# ================================================================\n",
        "# Reproducibility\n",
        "# ================================================================\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ================================================================\n",
        "# Load HeteroData graph\n",
        "# ================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"LOADING GRAPH DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "data = torch.load('graph.pt', weights_only=False)\n",
        "print(f\"\\nLoaded HeteroData with:\")\n",
        "print(f\"  - Node types: {list(data.node_types)}\")\n",
        "print(f\"  - Edge types: {len(data.edge_types)}\")\n",
        "\n",
        "num_compounds = data['Compound'].num_nodes\n",
        "num_diseases = data['Disease'].num_nodes\n",
        "print(f\"\\n  - Compounds: {num_compounds}\")\n",
        "print(f\"  - Diseases: {num_diseases}\")\n",
        "\n",
        "assert data['Compound'].num_nodes == num_compounds\n",
        "assert data['Disease'].num_nodes == num_diseases\n",
        "\n",
        "# ================================================================\n",
        "# Split treats relation\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SPLITTING EDGES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def split_edges(edge_index, train_ratio=0.7, val_ratio=0.15, seed=SEED):\n",
        "    torch.manual_seed(seed)\n",
        "    num_edges = edge_index.size(1)\n",
        "    perm = torch.randperm(num_edges)\n",
        "    train_end = int(train_ratio * num_edges)\n",
        "    val_end = train_end + int(val_ratio * num_edges)\n",
        "    return {\n",
        "        \"train\": edge_index[:, perm[:train_end]],\n",
        "        \"val\": edge_index[:, perm[train_end:val_end]],\n",
        "        \"test\": edge_index[:, perm[val_end:]]\n",
        "    }\n",
        "\n",
        "rel_treats = ('Compound', 'treats', 'Disease')\n",
        "orig_treats = data[rel_treats].edge_index\n",
        "splits_treats = split_edges(orig_treats)\n",
        "\n",
        "print(f\"\\n'treats' relation split:\")\n",
        "print(f\"  - Train: {splits_treats['train'].size(1)} edges\")\n",
        "print(f\"  - Val:   {splits_treats['val'].size(1)} edges\")\n",
        "print(f\"  - Test:  {splits_treats['test'].size(1)} edges\")\n",
        "\n",
        "# ================================================================\n",
        "# Build train_data (only treats edges reduced)\n",
        "# ================================================================\n",
        "train_data = data.clone()\n",
        "\n",
        "for rel in data.edge_types:\n",
        "    if rel == rel_treats:\n",
        "        train_data[rel].edge_index = splits_treats['train']\n",
        "    else:\n",
        "        train_data[rel].edge_index = data[rel].edge_index\n",
        "\n",
        "    src, name, dst = rel\n",
        "    rev = (dst, name + \"_rev\", src)\n",
        "    if rev in data.edge_types:\n",
        "        train_data[rev].edge_index = train_data[rel].edge_index.flip(0)\n",
        "\n",
        "# ================================================================\n",
        "# Heterogeneous ‚Üí Homogeneous conversion\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CONVERTING TO HOMOGENEOUS GRAPH\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def hetero_to_homo(hetero_data, default_dim=128):\n",
        "    node_offset = {}\n",
        "    offset = 0\n",
        "    feat_dim = None\n",
        "    node_features = []\n",
        "\n",
        "    for ntype in hetero_data.node_types:\n",
        "        node_offset[ntype] = offset\n",
        "        n = hetero_data[ntype].num_nodes\n",
        "\n",
        "        if hasattr(hetero_data[ntype], \"x\") and hetero_data[ntype].x is not None:\n",
        "            ft = hetero_data[ntype].x\n",
        "            if feat_dim is None:\n",
        "                feat_dim = ft.size(1)\n",
        "            else:\n",
        "                assert ft.size(1) == feat_dim\n",
        "        else:\n",
        "            if feat_dim is None:\n",
        "                feat_dim = default_dim\n",
        "            ft = torch.zeros((n, feat_dim))\n",
        "        offset += n\n",
        "        node_features.append(ft)\n",
        "\n",
        "    x = torch.cat(node_features, dim=0)\n",
        "    x = F.normalize(x, p=2, dim=1)\n",
        "\n",
        "    edge_index_list = []\n",
        "    edge_type_list = []\n",
        "    relation_names = []\n",
        "    relname2id = {}\n",
        "\n",
        "    for rel_id, edge_type in enumerate(hetero_data.edge_types):\n",
        "        src, relname, dst = edge_type\n",
        "        eidx = hetero_data[edge_type].edge_index.clone()\n",
        "        eidx[0] += node_offset[src]\n",
        "        eidx[1] += node_offset[dst]\n",
        "        edge_index_list.append(eidx)\n",
        "        edge_type_list.append(torch.full((eidx.size(1),), rel_id, dtype=torch.long))\n",
        "        relation_names.append(edge_type)\n",
        "        relname2id[edge_type] = rel_id\n",
        "\n",
        "    edge_index = torch.cat(edge_index_list, dim=1)\n",
        "    edge_type = torch.cat(edge_type_list, dim=0)\n",
        "\n",
        "    # Add self-loop relation\n",
        "    N = x.size(0)\n",
        "    loop_edges = torch.arange(N).unsqueeze(0).repeat(2, 1)\n",
        "    self_rel_id = len(relation_names)\n",
        "\n",
        "    edge_index = torch.cat([edge_index, loop_edges], dim=1)\n",
        "    edge_type = torch.cat([edge_type, torch.full((N,), self_rel_id)], dim=0)\n",
        "\n",
        "    relation_names.append(('SELF', 'SELF', 'SELF'))\n",
        "    relname2id[('SELF', 'SELF', 'SELF')] = self_rel_id\n",
        "\n",
        "    return x, edge_index, edge_type, node_offset, relation_names, relname2id\n",
        "\n",
        "x, edge_index, edge_type, node_offset, relation_names, relname2id = hetero_to_homo(train_data)\n",
        "treats_rel_id = relname2id[rel_treats]\n",
        "\n",
        "print(f\"\\nHomogeneous graph:\")\n",
        "print(f\"  - Total nodes: {x.size(0)}\")\n",
        "print(f\"  - Total edges: {edge_index.size(1)}\")\n",
        "print(f\"  - Relations: {len(relation_names)}\")\n",
        "print(f\"  - 'treats' relation ID: {treats_rel_id}\")\n",
        "\n",
        "# ================================================================\n",
        "# Negative Sampling\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"NEGATIVE SAMPLING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "pos_mat = np.zeros((num_compounds, num_diseases), dtype=bool)\n",
        "all_pos = torch.cat([splits_treats['train'], splits_treats['val'], splits_treats['test']], dim=1)\n",
        "pos_mat[all_pos[0].numpy(), all_pos[1].numpy()] = True\n",
        "\n",
        "def sample_neg(k):\n",
        "    negs = []\n",
        "    while len(negs) < k:\n",
        "        need = k - len(negs)\n",
        "        samp = max(need * 5, 1000)\n",
        "        c = np.random.randint(0, num_compounds, samp)\n",
        "        d = np.random.randint(0, num_diseases, samp)\n",
        "        mask = ~pos_mat[c, d]\n",
        "        gc = c[mask][:need]\n",
        "        gd = d[mask][:need]\n",
        "        for ci, di in zip(gc, gd):\n",
        "            negs.append([ci, di])\n",
        "    return torch.tensor(negs[:k]).t()\n",
        "\n",
        "neg_train = sample_neg(splits_treats['train'].size(1))\n",
        "neg_val = sample_neg(splits_treats['val'].size(1))\n",
        "neg_test = sample_neg(splits_treats['test'].size(1))\n",
        "\n",
        "print(f\"\\nNegative samples generated:\")\n",
        "print(f\"  - Train: {neg_train.size(1)}\")\n",
        "print(f\"  - Val:   {neg_val.size(1)}\")\n",
        "print(f\"  - Test:  {neg_test.size(1)}\")\n",
        "\n",
        "# ================================================================\n",
        "# R-GCN Model\n",
        "# ================================================================\n",
        "class RGCNLinkPredictor(nn.Module):\n",
        "    def __init__(self, in_dim, hid, num_rel, num_bases=8, dropout=0.2, temperature=1.0):\n",
        "        super().__init__()\n",
        "        self.conv1 = RGCNConv(in_dim, hid, num_rel, num_bases=num_bases)\n",
        "        self.conv2 = RGCNConv(hid, hid, num_rel, num_bases=num_bases)\n",
        "        self.norm1 = nn.LayerNorm(hid)\n",
        "        self.norm2 = nn.LayerNorm(hid)\n",
        "        self.relation_emb = nn.Parameter(torch.randn(num_rel, hid) * 0.1)\n",
        "        self.dropout = dropout\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def encode(self, x, ei, et):\n",
        "        h = self.conv1(x, ei, et)\n",
        "        h = self.norm1(h)\n",
        "        h = F.leaky_relu(h, 0.2)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        h = self.conv2(h, ei, et)\n",
        "        h = self.norm2(h)\n",
        "        h = F.leaky_relu(h, 0.2)\n",
        "        return F.normalize(h, dim=1)\n",
        "\n",
        "    def decode(self, z, edge_index, rel_ids):\n",
        "        z_src = z[edge_index[0]]\n",
        "        z_dst = z[edge_index[1]]\n",
        "        r = self.relation_emb[rel_ids]\n",
        "        return (z_src * r * z_dst).sum(dim=1) / self.temperature\n",
        "\n",
        "    def forward(self, x, ei, et, pred_edges, rel_ids):\n",
        "        z = self.encode(x, ei, et)\n",
        "        return self.decode(z, pred_edges, rel_ids)\n",
        "\n",
        "# ================================================================\n",
        "# Training Setup\n",
        "# ================================================================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\n\" + \"=\" * 80)\n",
        "print(f\"DEVICE: {device}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "model = RGCNLinkPredictor(x.size(1), 128, len(relation_names)).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "x = x.to(device)\n",
        "edge_index = edge_index.to(device)\n",
        "edge_type = edge_type.to(device)\n",
        "\n",
        "# ================================================================\n",
        "# Evaluation Function\n",
        "# ================================================================\n",
        "def evaluate(model, x, ei, et, pos_edges, neg_edges, node_offset, rel_id, k=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encode(x, ei, et)\n",
        "\n",
        "        pos = pos_edges.clone()\n",
        "        pos[0] += node_offset['Compound']\n",
        "        pos[1] += node_offset['Disease']\n",
        "        neg = neg_edges.clone()\n",
        "        neg[0] += node_offset['Compound']\n",
        "        neg[1] += node_offset['Disease']\n",
        "\n",
        "        pos = pos.to(device)\n",
        "        neg = neg.to(device)\n",
        "\n",
        "        rel_pos = torch.full((pos.size(1),), rel_id, dtype=torch.long, device=device)\n",
        "        rel_neg = torch.full((neg.size(1),), rel_id, dtype=torch.long, device=device)\n",
        "\n",
        "        pos_scores = torch.sigmoid(model.decode(z, pos, rel_pos)).cpu().numpy()\n",
        "        neg_scores = torch.sigmoid(model.decode(z, neg, rel_neg)).cpu().numpy()\n",
        "\n",
        "        y_true = np.concatenate([np.ones(len(pos_scores)), np.zeros(len(neg_scores))])\n",
        "        y_score = np.concatenate([pos_scores, neg_scores])\n",
        "\n",
        "        auc = roc_auc_score(y_true, y_score)\n",
        "        ap = average_precision_score(y_true, y_score)\n",
        "\n",
        "        # Compute Hits@K and MRR\n",
        "        hits_at_k = []\n",
        "        reciprocal_ranks = []\n",
        "        for i in range(len(pos_scores)):\n",
        "            pos_s = pos_scores[i]\n",
        "            rank = (neg_scores > pos_s).sum() + 1\n",
        "            hits_at_k.append(1.0 if rank <= k else 0.0)\n",
        "            reciprocal_ranks.append(1.0 / rank)\n",
        "\n",
        "        return {\n",
        "            \"auc\": auc,\n",
        "            \"ap\": ap,\n",
        "            f\"hits@{k}\": np.mean(hits_at_k),\n",
        "            \"mrr\": np.mean(reciprocal_ranks),\n",
        "            \"pos_prob\": pos_scores.mean(),\n",
        "            \"neg_prob\": neg_scores.mean()\n",
        "        }\n",
        "\n",
        "# ================================================================\n",
        "# Training Loop\n",
        "# ================================================================\n",
        "def train_epoch():\n",
        "    model.train()\n",
        "\n",
        "    pos = splits_treats['train'].clone()\n",
        "    pos[0] += node_offset['Compound']\n",
        "    pos[1] += node_offset['Disease']\n",
        "\n",
        "    neg = neg_train.clone()\n",
        "    neg[0] += node_offset['Compound']\n",
        "    neg[1] += node_offset['Disease']\n",
        "\n",
        "    pos = pos.to(device)\n",
        "    neg = neg.to(device)\n",
        "\n",
        "    rel_pos = torch.full((pos.size(1),), treats_rel_id, dtype=torch.long, device=device)\n",
        "    rel_neg = torch.full((neg.size(1),), treats_rel_id, dtype=torch.long, device=device)\n",
        "\n",
        "    pos_scores = model(x, edge_index, edge_type, pos, rel_pos)\n",
        "    neg_scores = model(x, edge_index, edge_type, neg, rel_neg)\n",
        "\n",
        "    logits = torch.cat([pos_scores, neg_scores])\n",
        "    labels = torch.cat([torch.ones_like(pos_scores), torch.zeros_like(neg_scores)])\n",
        "\n",
        "    loss = F.binary_cross_entropy_with_logits(logits, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pos_prob = torch.sigmoid(pos_scores).mean().item()\n",
        "        neg_prob = torch.sigmoid(neg_scores).mean().item()\n",
        "\n",
        "    return loss.item(), pos_prob, neg_prob\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TRAINING\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n{'Epoch':<8} {'Loss':<10} {'Pos Prob':<10} {'Neg Prob':<10} {'ROC-AUC':<10} {'AP':<10} {'Hits@10':<10} {'MRR':<10}\")\n",
        "print(\"-\" * 88)\n",
        "\n",
        "best_auc = 0\n",
        "for epoch in range(1, 201):\n",
        "    loss, pos_prob, neg_prob = train_epoch()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        val_metrics = evaluate(model, x, edge_index, edge_type, splits_treats['val'],\n",
        "                               neg_val, node_offset, treats_rel_id)\n",
        "\n",
        "        print(f\"{epoch:<8} {loss:<10.4f} {pos_prob:<10.4f} {neg_prob:<10.4f} \"\n",
        "              f\"{val_metrics['auc']:<10.4f} {val_metrics['ap']:<10.4f} \"\n",
        "              f\"{val_metrics['hits@10']:<10.4f} {val_metrics['mrr']:<10.4f}\")\n",
        "\n",
        "        if val_metrics[\"auc\"] > best_auc:\n",
        "            best_auc = val_metrics[\"auc\"]\n",
        "            torch.save(model.state_dict(), \"best_rgcn_model.pt\")\n",
        "\n",
        "# ================================================================\n",
        "# Test Evaluation\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"TEST EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "model.load_state_dict(torch.load(\"best_rgcn_model.pt\"))\n",
        "test_metrics = evaluate(model, x, edge_index, edge_type, splits_treats['test'],\n",
        "                        neg_test, node_offset, treats_rel_id)\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"  - ROC-AUC:  {test_metrics['auc']:.4f}\")\n",
        "print(f\"  - AP:       {test_metrics['ap']:.4f}\")\n",
        "print(f\"  - Hits@10:  {test_metrics['hits@10']:.4f}\")\n",
        "print(f\"  - MRR:      {test_metrics['mrr']:.4f}\")\n",
        "\n",
        "# ================================================================\n",
        "# Predict all compound-disease pairs\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GENERATING PREDICTIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def predict_all_pairs():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        z = model.encode(x, edge_index, edge_type)\n",
        "        comp_start = node_offset['Compound']\n",
        "        dis_start = node_offset['Disease']\n",
        "\n",
        "        zc = z[comp_start : comp_start + num_compounds]\n",
        "        zd = z[dis_start : dis_start + num_diseases]\n",
        "\n",
        "        r = model.relation_emb[treats_rel_id]\n",
        "        scores = torch.sigmoid((zc * r) @ zd.T)\n",
        "        return scores.cpu().numpy()\n",
        "\n",
        "scores = predict_all_pairs()\n",
        "np.save(\"compound_disease_predictions.npy\", scores)\n",
        "print(f\"\\nSaved full prediction matrix: {scores.shape}\")\n",
        "\n",
        "# ================================================================\n",
        "# Create CSV with Top-10 predictions per compound\n",
        "# ================================================================\n",
        "print(\"\\nCreating top-10 predictions CSV...\")\n",
        "\n",
        "# Build set of existing positive edges\n",
        "existing_edges = set()\n",
        "for i in range(all_pos.size(1)):\n",
        "    existing_edges.add((all_pos[0, i].item(), all_pos[1, i].item()))\n",
        "\n",
        "rows = []\n",
        "for compound_id in range(num_compounds):\n",
        "    # Get all scores for this compound\n",
        "    compound_scores = scores[compound_id]\n",
        "\n",
        "    # Get top-10 disease indices\n",
        "    top10_indices = np.argsort(compound_scores)[-10:][::-1]\n",
        "\n",
        "    for rank, disease_id in enumerate(top10_indices, 1):\n",
        "        score = float(compound_scores[disease_id])\n",
        "\n",
        "        # Check if this is an existing positive edge\n",
        "        is_positive = (compound_id, disease_id) in existing_edges\n",
        "        edge_type = \"Positive\" if is_positive else \"Negative (New Prediction)\"\n",
        "\n",
        "        rows.append({\n",
        "            'Compound_ID': compound_id,\n",
        "            'Disease_ID': disease_id,\n",
        "            'Rank': rank,\n",
        "            'Score': score,\n",
        "            'Edge_Type': edge_type\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv('top10_disease_predictions_per_compound.csv', index=False)\n",
        "\n",
        "print(f\"Saved: top10_disease_predictions_per_compound.csv\")\n",
        "print(f\"  - Total predictions: {len(df)}\")\n",
        "print(f\"  - Positive edges: {(df['Edge_Type'] == 'Positive').sum()}\")\n",
        "print(f\"  - Negative edges (new): {(df['Edge_Type'] == 'Negative (New Prediction)').sum()}\")\n",
        "\n",
        "# ================================================================\n",
        "# Query Functions for Specific Compounds\n",
        "# ================================================================\n",
        "\n",
        "def predict_for_compound(compound_id, top_k=10):\n",
        "    \"\"\"\n",
        "    Get top-K disease predictions for a specific compound.\n",
        "\n",
        "    Args:\n",
        "        compound_id: Integer ID of the compound\n",
        "        top_k: Number of top predictions to return\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with predictions\n",
        "    \"\"\"\n",
        "    if compound_id < 0 or compound_id >= num_compounds:\n",
        "        raise ValueError(f\"Invalid compound_id. Must be between 0 and {num_compounds-1}\")\n",
        "\n",
        "    compound_scores = scores[compound_id]\n",
        "    top_indices = np.argsort(compound_scores)[-top_k:][::-1]\n",
        "\n",
        "    results = []\n",
        "    for rank, disease_id in enumerate(top_indices, 1):\n",
        "        score = float(compound_scores[disease_id])\n",
        "        is_positive = (compound_id, disease_id) in existing_edges\n",
        "        edge_type = \"Positive\" if is_positive else \"Negative (New Prediction)\"\n",
        "\n",
        "        results.append({\n",
        "            'Compound_ID': compound_id,\n",
        "            'Disease_ID': disease_id,\n",
        "            'Rank': rank,\n",
        "            'Score': score,\n",
        "            'Edge_Type': edge_type\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def predict_for_compounds(compound_ids, top_k=10):\n",
        "    \"\"\"\n",
        "    Get top-K disease predictions for multiple compounds.\n",
        "\n",
        "    Args:\n",
        "        compound_ids: List of compound IDs\n",
        "        top_k: Number of top predictions per compound\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with all predictions\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "    for cid in compound_ids:\n",
        "        df_temp = predict_for_compound(cid, top_k)\n",
        "        all_results.append(df_temp)\n",
        "\n",
        "    return pd.concat(all_results, ignore_index=True)\n",
        "\n",
        "def predict_compound_disease_pair(compound_id, disease_id):\n",
        "    \"\"\"\n",
        "    Get prediction score for a specific compound-disease pair.\n",
        "\n",
        "    Args:\n",
        "        compound_id: Integer ID of the compound\n",
        "        disease_id: Integer ID of the disease\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with prediction details\n",
        "    \"\"\"\n",
        "    if compound_id < 0 or compound_id >= num_compounds:\n",
        "        raise ValueError(f\"Invalid compound_id. Must be between 0 and {num_compounds-1}\")\n",
        "    if disease_id < 0 or disease_id >= num_diseases:\n",
        "        raise ValueError(f\"Invalid disease_id. Must be between 0 and {num_diseases-1}\")\n",
        "\n",
        "    score = float(scores[compound_id, disease_id])\n",
        "    is_positive = (compound_id, disease_id) in existing_edges\n",
        "\n",
        "    return {\n",
        "        'Compound_ID': compound_id,\n",
        "        'Disease_ID': disease_id,\n",
        "        'Score': score,\n",
        "        'Edge_Type': \"Positive\" if is_positive else \"Negative (New Prediction)\"\n",
        "    }\n",
        "\n",
        "# ================================================================\n",
        "# Example Usage\n",
        "# ================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"QUERY EXAMPLES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Example 1: Single compound\n",
        "print(\"\\n[1] Predictions for Compound ID = 0:\")\n",
        "result1 = predict_for_compound(compound_id=0, top_k=5)\n",
        "print(result1.to_string(index=False))\n",
        "\n",
        "# Example 2: Multiple compounds\n",
        "print(\"\\n[2] Predictions for Compounds [5, 10, 15]:\")\n",
        "result2 = predict_for_compounds(compound_ids=[5, 10, 15], top_k=3)\n",
        "print(result2.to_string(index=False))\n",
        "\n",
        "# Example 3: Specific pair\n",
        "print(\"\\n[3] Prediction for Compound 0 - Disease 10:\")\n",
        "result3 = predict_compound_disease_pair(compound_id=0, disease_id=10)\n",
        "print(f\"  Score: {result3['Score']:.4f}\")\n",
        "print(f\"  Edge Type: {result3['Edge_Type']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPLETED SUCCESSFULLY\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nüìã AVAILABLE FUNCTIONS:\")\n",
        "print(\"  ‚Ä¢ predict_for_compound(compound_id, top_k=10)\")\n",
        "print(\"  ‚Ä¢ predict_for_compounds(compound_ids, top_k=10)\")\n",
        "print(\"  ‚Ä¢ predict_compound_disease_pair(compound_id, disease_id)\")\n",
        "print(\"\\nüíæ SAVED FILES:\")\n",
        "print(\"  ‚Ä¢ compound_disease_predictions.npy - Full prediction matrix\")\n",
        "print(\"  ‚Ä¢ top10_disease_predictions_per_compound.csv - All compounds top-10\")\n",
        "print(\"  ‚Ä¢ best_rgcn_model.pt - Trained model weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5Z06ULvWqjV",
        "outputId": "5daa2921-a79a-475f-e4d8-46f792ebaa43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "LOADING GRAPH DATA\n",
            "================================================================================\n",
            "\n",
            "Loaded HeteroData with:\n",
            "  - Node types: ['Anatomy', 'Biological_Process', 'Cellular_Component', 'Compound', 'Disease', 'Gene', 'Molecular_Function', 'Pathway', 'Pharmacologic_Class', 'Side_Effect', 'Symptom']\n",
            "  - Edge types: 38\n",
            "\n",
            "  - Compounds: 1552\n",
            "  - Diseases: 137\n",
            "\n",
            "================================================================================\n",
            "SPLITTING EDGES\n",
            "================================================================================\n",
            "\n",
            "'treats' relation split:\n",
            "  - Train: 528 edges\n",
            "  - Val:   113 edges\n",
            "  - Test:  114 edges\n",
            "\n",
            "================================================================================\n",
            "CONVERTING TO HOMOGENEOUS GRAPH\n",
            "================================================================================\n",
            "\n",
            "Homogeneous graph:\n",
            "  - Total nodes: 47031\n",
            "  - Total edges: 4498632\n",
            "  - Relations: 39\n",
            "  - 'treats' relation ID: 14\n",
            "\n",
            "================================================================================\n",
            "NEGATIVE SAMPLING\n",
            "================================================================================\n",
            "\n",
            "Negative samples generated:\n",
            "  - Train: 528\n",
            "  - Val:   113\n",
            "  - Test:  114\n",
            "\n",
            "================================================================================\n",
            "DEVICE: cuda\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "TRAINING\n",
            "================================================================================\n",
            "\n",
            "Epoch    Loss       Pos Prob   Neg Prob   ROC-AUC    AP         Hits@10    MRR       \n",
            "----------------------------------------------------------------------------------------\n",
            "10       0.6837     0.5078     0.4982     0.8826     0.8776     0.5841     0.2990    \n",
            "20       0.6651     0.5226     0.4938     0.9288     0.9361     0.7345     0.6281    \n",
            "30       0.6454     0.5339     0.4843     0.9422     0.9461     0.7611     0.5779    \n",
            "40       0.6286     0.5431     0.4754     0.9518     0.9537     0.8673     0.5512    \n",
            "50       0.6146     0.5500     0.4673     0.9522     0.9505     0.9027     0.4716    \n",
            "60       0.6029     0.5547     0.4592     0.9479     0.9410     0.8850     0.3978    \n",
            "70       0.5923     0.5585     0.4513     0.9459     0.9359     0.8407     0.3682    \n",
            "80       0.5849     0.5624     0.4468     0.9443     0.9314     0.8230     0.3370    \n",
            "90       0.5769     0.5653     0.4408     0.9414     0.9269     0.8142     0.3172    \n",
            "100      0.5688     0.5694     0.4356     0.9432     0.9296     0.8230     0.3276    \n",
            "110      0.5598     0.5734     0.4295     0.9400     0.9216     0.8407     0.2907    \n",
            "120      0.5516     0.5759     0.4225     0.9382     0.9282     0.7965     0.3480    \n",
            "130      0.5413     0.5820     0.4167     0.9286     0.9070     0.7699     0.2652    \n",
            "140      0.5318     0.5882     0.4115     0.9171     0.8885     0.7257     0.2234    \n",
            "150      0.5242     0.5931     0.4070     0.8929     0.8142     0.4425     0.1148    \n",
            "160      0.5146     0.5994     0.4015     0.8826     0.7941     0.4336     0.1008    \n",
            "170      0.5077     0.6032     0.3966     0.8792     0.7904     0.4513     0.0988    \n",
            "180      0.5005     0.6070     0.3915     0.8790     0.8063     0.3363     0.1175    \n",
            "190      0.4948     0.6125     0.3899     0.8782     0.8000     0.3894     0.1084    \n",
            "200      0.4894     0.6152     0.3859     0.8852     0.8117     0.4779     0.1163    \n",
            "\n",
            "================================================================================\n",
            "TEST EVALUATION\n",
            "================================================================================\n",
            "\n",
            "Test Results:\n",
            "  - ROC-AUC:  0.9358\n",
            "  - AP:       0.9186\n",
            "  - Hits@10:  0.7368\n",
            "  - MRR:      0.2846\n",
            "\n",
            "================================================================================\n",
            "GENERATING PREDICTIONS\n",
            "================================================================================\n",
            "\n",
            "Saved full prediction matrix: (1552, 137)\n",
            "\n",
            "Creating top-10 predictions CSV...\n",
            "Saved: top10_disease_predictions_per_compound.csv\n",
            "  - Total predictions: 15520\n",
            "  - Positive edges: 355\n",
            "  - Negative edges (new): 15165\n",
            "\n",
            "================================================================================\n",
            "QUERY EXAMPLES\n",
            "================================================================================\n",
            "\n",
            "[1] Predictions for Compound ID = 0:\n",
            " Compound_ID  Disease_ID  Rank    Score                 Edge_Type\n",
            "           0           9     1 0.535933 Negative (New Prediction)\n",
            "           0          92     2 0.534960 Negative (New Prediction)\n",
            "           0           1     3 0.534819 Negative (New Prediction)\n",
            "           0          35     4 0.534201 Negative (New Prediction)\n",
            "           0         129     5 0.534038 Negative (New Prediction)\n",
            "\n",
            "[2] Predictions for Compounds [5, 10, 15]:\n",
            " Compound_ID  Disease_ID  Rank    Score                 Edge_Type\n",
            "           5           1     1 0.496779 Negative (New Prediction)\n",
            "           5           9     2 0.495757 Negative (New Prediction)\n",
            "           5          92     3 0.494978 Negative (New Prediction)\n",
            "          10           1     1 0.534654 Negative (New Prediction)\n",
            "          10           9     2 0.534327 Negative (New Prediction)\n",
            "          10         129     3 0.533424 Negative (New Prediction)\n",
            "          15           1     1 0.544419 Negative (New Prediction)\n",
            "          15           9     2 0.544090 Negative (New Prediction)\n",
            "          15          92     3 0.543732 Negative (New Prediction)\n",
            "\n",
            "[3] Prediction for Compound 0 - Disease 10:\n",
            "  Score: 0.4608\n",
            "  Edge Type: Negative (New Prediction)\n",
            "\n",
            "================================================================================\n",
            "COMPLETED SUCCESSFULLY\n",
            "================================================================================\n",
            "\n",
            "üìã AVAILABLE FUNCTIONS:\n",
            "  ‚Ä¢ predict_for_compound(compound_id, top_k=10)\n",
            "  ‚Ä¢ predict_for_compounds(compound_ids, top_k=10)\n",
            "  ‚Ä¢ predict_compound_disease_pair(compound_id, disease_id)\n",
            "\n",
            "üíæ SAVED FILES:\n",
            "  ‚Ä¢ compound_disease_predictions.npy - Full prediction matrix\n",
            "  ‚Ä¢ top10_disease_predictions_per_compound.csv - All compounds top-10\n",
            "  ‚Ä¢ best_rgcn_model.pt - Trained model weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwY9usFpPSe7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}